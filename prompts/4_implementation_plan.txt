Создай implementation_plan.mdc  
(alwaysApply: false).

Требования:
* 3–4 этапа (Milestone 1, 2, 3 …).
* Внутри каждого — список задач в формате  
  - TODO: …  
  - TODO: …  
* Внизу файла добавь раздел Acceptance Checklist (список критериев готовности).
* В самом конце вставь инструкцию, чтобы Cursor сам отмечал выполненное:  

> **@Cursor**: После завершения задачи поменяй её статус на DONE и добавь краткий маркер «// done by Cursor» с описанием, что именно сделано.

Ответ — полный .mdc-файл. Он должен быть очень подробный, начинающийся с собственно создания структуры приложения. Вначале нужно указать, что у каждого пункта есть статус, и нужно начинать работу с первого невыполненного.

Заметки
Часто возникающие проблемы, которые нужно учесть при разработке:
• ВАЖНО: Создать .gitignore ПЕРЕД первым коммитом, включив .env файлы
• Добавить python-dotenv в зависимости для загрузки локальных переменных окружения

• Создать Dockerfile на базе python:3.12-slim
  ВАЖНО: Порядок операций критичен для editable install:
  1. COPY pyproject.toml ./
  2. COPY src/ ./src/  # ОБЯЗАТЕЛЬНО перед pip install -e .
  3. RUN pip install --no-cache-dir -e .
• Создать .dockerignore для оптимизации контекста сборки

• ВНИМАНИЕ: Исправить запуск asyncio для контейнерной среды
  - НЕ использовать asyncio.run() в main
  - Вызывать application.run_webhook/run_polling напрямую
  - python-telegram-bot управляет event loop самостоятельно

Дополнительные требования для тестирования:

• Milestone 0: "Test Data Preparation via Wikipedia API"
  - TODO: Установить библиотеки для работы с Wikipedia API (requests, wikipedia-api)
  - TODO: Создать wikipedia_parser.py с классом WikipediaParser
  - TODO: Реализовать парсинг категорий достопримечательностей
  - TODO: Добавить извлечение координат из geo-данных статей
  - TODO: Создать фильтрацию и валидацию данных
  - TODO: Генерация JSON датасета с 50+ локациями
  - TODO: Создать CLI интерфейс для управления парсингом
  - TODO: Интегрировать с основным тестовым модулем

• Milestone "Testing Infrastructure":
  - TODO: Создать test_location_recognition.py 
  - TODO: Реализовать функцию сравнения результатов GPT с эталонными данными
  - TODO: Добавить метрики точности (accuracy, precision для названий мест)
  - TODO: Создать скрипт для batch-тестирования всех координат из датасета
  - TODO: Логирование результатов тестирования в CSV/JSON

• Milestone "Validation & Metrics":
  - TODO: Интеграция с GPT-4.1-mini для валидации результатов
  - TODO: Создание промпта для GPT: "Проверь, соответствует ли описание '{gpt_result}' месту с координатами {lat}, {lon}"
  - TODO: Автоматический расчет accuracy rate
  - TODO: Генерация отчета о качестве распознавания мест

Дополнительные пункты в Acceptance Checklist:
□ Wikipedia parser успешно извлекает данные о 50+ достопримечательностях
□ Все локации имеют валидные координаты и описания
□ Тестовый датасет автоматически обновляется из Wikipedia
□ Парсер обрабатывает как русские, так и английские категории
□ JSON файл с тестовыми данными готов к использованию
□ Тестовый датасет содержит минимум 15 разных типов мест (музеи, парки, памятники, etc.)
□ Accuracy rate определения места > 80% на тестовом датасете  
□ GPT-валидация подтверждает корректность минимум 85% результатов
□ Все результаты тестирования сохраняются и доступны для анализа
□ Есть возможность запустить полное тестирование одной командой